{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import io\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import seaborn as sns\n",
    "import sklearn.model_selection\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.nn import init\n",
    "import torch.utils.data as info_data\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = io.loadmat('Datasets/IndianPines/Indian_pines_corrected.mat')\n",
    "images = loaded_dataset['indian_pines_corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = io.loadmat('Datasets/IndianPines/Indian_pines_gt.mat')\n",
    "ground_truth = ground_truth['indian_pines_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_bands = (43, 21, 11)  # AVIRIS sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_values = [\"Undefined\", \"Alfalfa\", \"Corn-notill\", \"Corn-mintill\",\n",
    "                        \"Corn\", \"Grass-pasture\", \"Grass-trees\",\n",
    "                        \"Grass-pasture-mowed\", \"Hay-windrowed\", \"Oats\",\n",
    "                        \"Soybean-notill\", \"Soybean-mintill\", \"Soybean-clean\",\n",
    "                        \"Wheat\", \"Woods\", \"Buildings-Grass-Trees-Drives\",\n",
    "                        \"Stone-Steel-Towers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ignored_labels = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To check if there is nan data\n",
    "nan_mask = np.isnan(images.sum(axis=-1))\n",
    "np.count_nonzero(nan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "images[nan_mask] = 0\n",
    "ground_truth[nan_mask] = 0\n",
    "ignored_labels.append(0)\n",
    "ignored_labels = list(set(ignored_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.asarray(images, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = images.reshape(np.prod(images.shape[:2]), np.prod(images.shape[2:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21025, 200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = preprocessing.minmax_scale(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = data.reshape(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = len(label_values)\n",
    "N_BANDS = images.shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined palette\n",
    "palette = {0: (0, 0, 0)}\n",
    "for k, color in enumerate(sns.color_palette(\"hls\", len(label_values) - 1)):\n",
    "    palette[k + 1] = tuple(np.asarray(255 * np.array(color), dtype='uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defined inverted palette\n",
    "invert_palette = {v: k for k, v in palette.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_gt(gt, train_size, mode='random'):\n",
    "    \"\"\"Extract a fixed percentage of samples from an array of labels.\n",
    "\n",
    "    Args:\n",
    "        gt: a 2D array of int labels\n",
    "        percentage: [0, 1] float\n",
    "    Returns:\n",
    "        train_gt, test_gt: 2D arrays of int labels\n",
    "\n",
    "    \"\"\"\n",
    "    indices = np.nonzero(gt)\n",
    "    X = list(zip(*indices)) # x,y features\n",
    "    y = gt[indices].ravel() # classes\n",
    "    train_gt = np.zeros_like(gt)\n",
    "    test_gt = np.zeros_like(gt)\n",
    "    if train_size > 1:\n",
    "       train_size = int(train_size)\n",
    "    \n",
    "    if mode == 'random':\n",
    "       train_indices, test_indices = sklearn.model_selection.train_test_split(X, train_size=train_size, stratify=y)\n",
    "       train_indices = [list(t) for t in zip(*train_indices)]\n",
    "       test_indices = [list(t) for t in zip(*test_indices)]\n",
    "       train_gt[train_indices] = gt[train_indices]\n",
    "       test_gt[test_indices] = gt[test_indices]\n",
    "    elif mode == 'fixed':\n",
    "       print(\"Sampling {} with train size = {}\".format(mode, train_size))\n",
    "       train_indices, test_indices = [], []\n",
    "       for c in np.unique(gt):\n",
    "           if c == 0:\n",
    "              continue\n",
    "           indices = np.nonzero(gt == c)\n",
    "           X = list(zip(*indices)) # x,y features\n",
    "\n",
    "           train, test = sklearn.model_selection.train_test_split(X, train_size=train_size)\n",
    "           train_indices += train\n",
    "           test_indices += test\n",
    "       train_indices = [list(t) for t in zip(*train_indices)]\n",
    "       test_indices = [list(t) for t in zip(*test_indices)]\n",
    "       train_gt[train_indices] = gt[train_indices]\n",
    "       test_gt[test_indices] = gt[test_indices]\n",
    "\n",
    "    elif mode == 'disjoint':\n",
    "        train_gt = np.copy(gt)\n",
    "        test_gt = np.copy(gt)\n",
    "        for c in np.unique(gt):\n",
    "            mask = gt == c\n",
    "            for x in range(gt.shape[0]):\n",
    "                first_half_count = np.count_nonzero(mask[:x, :])\n",
    "                second_half_count = np.count_nonzero(mask[x:, :])\n",
    "                try:\n",
    "                    ratio = first_half_count / second_half_count\n",
    "                    if ratio > 0.9 * train_size and ratio < 1.1 * train_size:\n",
    "                        break\n",
    "                except ZeroDivisionError:\n",
    "                    continue\n",
    "            mask[:x, :] = 0\n",
    "            train_gt[mask] = 0\n",
    "\n",
    "        test_gt[train_gt > 0] = 0\n",
    "    else:\n",
    "        raise ValueError(\"{} sampling is not implemented yet.\".format(mode))\n",
    "    return train_gt, test_gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Baseline(nn.Module):\n",
    "    \"\"\"\n",
    "    Baseline network\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def weight_init(m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            init.kaiming_normal_(m.weight)\n",
    "            init.zeros_(m.bias)\n",
    "\n",
    "    def __init__(self, input_channels, n_classes, dropout=False):\n",
    "        super(Baseline, self).__init__()\n",
    "        self.use_dropout = dropout\n",
    "        if dropout:\n",
    "            self.dropout = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.fc1 = nn.Linear(input_channels, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 4096)\n",
    "        self.fc3 = nn.Linear(4096, 2048)\n",
    "        self.fc4 = nn.Linear(2048, n_classes)\n",
    "\n",
    "        self.apply(self.weight_init)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        if self.use_dropout:\n",
    "            x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperX(torch.utils.data.Dataset):\n",
    "    \"\"\" Generic class for a hyperspectral scene \"\"\"\n",
    "\n",
    "    def __init__(self, data, gt, patch_size, center_pixel, flip_augmentation, radiation_augmentation, mixture_augmentation, supervision):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data: 3D hyperspectral image\n",
    "            gt: 2D array of labels\n",
    "            patch_size: int, size of the spatial neighbourhood\n",
    "            center_pixel: bool, set to True to consider only the label of the\n",
    "                          center pixel\n",
    "            data_augmentation: bool, set to True to perform random flips\n",
    "            supervision: 'full' or 'semi' supervised algorithms\n",
    "        \"\"\"\n",
    "        super(HyperX, self).__init__()\n",
    "        self.data = data\n",
    "        self.label = gt\n",
    "        self.name = 'IndianPines'\n",
    "        self.patch_size = patch_size\n",
    "        self.ignored_labels = [0]\n",
    "        self.flip_augmentation = flip_augmentation\n",
    "        self.radiation_augmentation = radiation_augmentation\n",
    "        self.mixture_augmentation = mixture_augmentation\n",
    "        self.center_pixel = center_pixel\n",
    "        supervision = supervision\n",
    "        # Fully supervised : use all pixels with label not ignored\n",
    "        if supervision == 'full':\n",
    "            mask = np.ones_like(gt)\n",
    "            for l in self.ignored_labels:\n",
    "                mask[gt == l] = 0\n",
    "        # Semi-supervised : use all pixels, except padding\n",
    "        elif supervision == 'semi':\n",
    "            mask = np.ones_like(gt)\n",
    "        x_pos, y_pos = np.nonzero(mask)\n",
    "        p = self.patch_size // 2\n",
    "        self.indices = np.array([(x,y) for x,y in zip(x_pos, y_pos) if x > p and x < data.shape[0] - p and y > p and y < data.shape[1] - p])\n",
    "        self.labels = [self.label[x,y] for x,y in self.indices]\n",
    "        np.random.shuffle(self.indices)\n",
    "\n",
    "    @staticmethod\n",
    "    def flip(*arrays):\n",
    "        horizontal = np.random.random() > 0.5\n",
    "        vertical = np.random.random() > 0.5\n",
    "        if horizontal:\n",
    "            arrays = [np.fliplr(arr) for arr in arrays]\n",
    "        if vertical:\n",
    "            arrays = [np.flipud(arr) for arr in arrays]\n",
    "        return arrays\n",
    "\n",
    "    @staticmethod\n",
    "    def radiation_noise(data, alpha_range=(0.9, 1.1), beta=1/25):\n",
    "        alpha = np.random.uniform(*alpha_range)\n",
    "        noise = np.random.normal(loc=0., scale=1.0, size=data.shape)\n",
    "        return alpha * data + beta * noise\n",
    "\n",
    "    def mixture_noise(self, data, label, beta=1/25):\n",
    "        alpha1, alpha2 = np.random.uniform(0.01, 1., size=2)\n",
    "        noise = np.random.normal(loc=0., scale=1.0, size=data.shape)\n",
    "        data2 = np.zeros_like(data)\n",
    "        for  idx, value in np.ndenumerate(label):\n",
    "            if value not in self.ignored_labels:\n",
    "                l_indices = np.nonzero(self.labels == value)[0]\n",
    "                l_indice = np.random.choice(l_indices)\n",
    "                assert(self.labels[l_indice] == value)\n",
    "                x, y = self.indices[l_indice]\n",
    "                data2[idx] = self.data[x,y]\n",
    "        return (alpha1 * data + alpha2 * data2) / (alpha1 + alpha2) + beta * noise\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.indices[i]\n",
    "        x1, y1 = x - self.patch_size // 2, y - self.patch_size // 2\n",
    "        x2, y2 = x1 + self.patch_size, y1 + self.patch_size\n",
    "\n",
    "        data = self.data[x1:x2, y1:y2]\n",
    "        label = self.label[x1:x2, y1:y2]\n",
    "\n",
    "        if self.flip_augmentation and self.patch_size > 1:\n",
    "            # Perform data augmentation (only on 2D patches)\n",
    "            data, label = self.flip(data, label)\n",
    "        if self.radiation_augmentation and np.random.random() < 0.1:\n",
    "                data = self.radiation_noise(data)\n",
    "        if self.mixture_augmentation and np.random.random() < 0.2:\n",
    "                data = self.mixture_noise(data, label)\n",
    "\n",
    "        # Copy the data into numpy arrays (PyTorch doesn't like numpy views)\n",
    "        data = np.asarray(np.copy(data).transpose((2, 0, 1)), dtype='float32')\n",
    "        label = np.asarray(np.copy(label), dtype='int64')\n",
    "\n",
    "        # Load the data into PyTorch tensors\n",
    "        data = torch.from_numpy(data)\n",
    "        label = torch.from_numpy(label)\n",
    "        # Extract the center label if needed\n",
    "        if self.center_pixel and self.patch_size > 1:\n",
    "            label = label[self.patch_size // 2, self.patch_size // 2]\n",
    "        # Remove unused dimensions when we work with invidual spectrums\n",
    "        elif self.patch_size == 1:\n",
    "            data = data[:, 0, 0]\n",
    "            label = label[0, 0]\n",
    "\n",
    "        # Add a fourth dimension for 3D CNN\n",
    "        if self.patch_size > 1:\n",
    "            # Make 4D data ((Batch x) Planes x Channels x Width x Height)\n",
    "            data = data.unsqueeze(0)\n",
    "        return data, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(prediction, target, ignored_labels=[], n_classes=None):\n",
    "    \"\"\"Compute and print metrics (accuracy, confusion matrix and F1 scores).\n",
    "\n",
    "    Args:\n",
    "        prediction: list of predicted labels\n",
    "        target: list of target labels\n",
    "        ignored_labels (optional): list of labels to ignore, e.g. 0 for undef\n",
    "        n_classes (optional): number of classes, max(target) by default\n",
    "    Returns:\n",
    "        accuracy, F1 score by class, confusion matrix\n",
    "    \"\"\"\n",
    "    ignored_mask = np.zeros(target.shape[:2], dtype=np.bool)\n",
    "    for l in ignored_labels:\n",
    "        ignored_mask[target == l] = True\n",
    "    ignored_mask = ~ignored_mask\n",
    "    #target = target[ignored_mask] -1\n",
    "    target = target[ignored_mask]\n",
    "    prediction = prediction[ignored_mask]\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    n_classes = np.max(target) + 1 if n_classes is None else n_classes\n",
    "    print('Target\\n',target)\n",
    "    print('Prediction\\n', prediction)\n",
    "    cm = confusion_matrix(\n",
    "        target,\n",
    "        prediction,\n",
    "        labels=range(n_classes))\n",
    "    print(cm)\n",
    "    results[\"Confusion matrix\"] = cm\n",
    "\n",
    "    # Compute global accuracy\n",
    "    total = np.sum(cm)\n",
    "    accuracy = sum([cm[x][x] for x in range(len(cm))])\n",
    "    accuracy *= 100 / float(total)\n",
    "\n",
    "    results[\"Accuracy\"] = accuracy\n",
    "\n",
    "    # Compute F1 score\n",
    "    F1scores = np.zeros(len(cm))\n",
    "    for i in range(len(cm)):\n",
    "        try:\n",
    "            print((np.sum(cm[i, :]) + np.sum(cm[:, i])))\n",
    "            F1 = 2. * cm[i, i] / (np.sum(cm[i, :]) + np.sum(cm[:, i]))\n",
    "        except ZeroDivisionError:\n",
    "            F1 = 0.\n",
    "        \n",
    "        F1scores[i] = F1\n",
    "\n",
    "    results[\"F1 scores\"] = F1scores\n",
    "\n",
    "    # Compute kappa coefficient\n",
    "    pa = np.trace(cm) / float(total)\n",
    "    pe = np.sum(np.sum(cm, axis=0) * np.sum(cm, axis=1)) / \\\n",
    "        float(total * total)\n",
    "    kappa = (pa - pe) / (1 - pe)\n",
    "    results[\"Kappa\"] = kappa\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def camel_to_snake(name):\n",
    "    s = re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', name)\n",
    "    return re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', s).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(n, iterable):\n",
    "    \"\"\" Browse an iterable by grouping n elements by n elements.\n",
    "\n",
    "    Args:\n",
    "        n: int, size of the groups\n",
    "        iterable: the iterable to Browse\n",
    "    Yields:\n",
    "        chunk of n elements from the iterable\n",
    "\n",
    "    \"\"\"\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, n))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield chunk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, model_name, dataset_name, **kwargs):\n",
    "    model_dir = './checkpoints/' + model_name + \"/\" + dataset_name + \"/\"\n",
    "    if not os.path.isdir(model_dir):\n",
    "        os.makedirs(model_dir, exist_ok=True)\n",
    "    if isinstance(model, torch.nn.Module):\n",
    "        filename = str('run') + \"_epoch{epoch}_{metric:.2f}\".format(**kwargs)\n",
    "        tqdm.write(\"Saving neural network weights in {}\".format(filename))\n",
    "        torch.save(model.state_dict(), model_dir + filename + '.pth')\n",
    "    else:\n",
    "        filename = str('run')\n",
    "        tqdm.write(\"Saving model params in {}\".format(filename))\n",
    "        joblib.dump(model, model_dir + filename + '.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, optimizer, criterion, data_loader, epoch, scheduler=None,\n",
    "          display_iter=False, device=torch.device('cpu'), display=None,\n",
    "          val_loader=None, supervision='full'):\n",
    "    \"\"\"\n",
    "    Training loop to optimize a network for several epochs and a specified loss\n",
    "\n",
    "    Args:\n",
    "        net: a PyTorch model\n",
    "        optimizer: a PyTorch optimizer\n",
    "        data_loader: a PyTorch dataset loader\n",
    "        epoch: int specifying the number of training epochs\n",
    "        criterion: a PyTorch-compatible loss function, e.g. nn.CrossEntropyLoss\n",
    "        device (optional): torch device to use (defaults to CPU)\n",
    "        display_iter (optional): number of iterations before refreshing the\n",
    "        display (False/None to switch off).\n",
    "        scheduler (optional): PyTorch scheduler\n",
    "        val_loader (optional): validation dataset\n",
    "        supervision (optional): 'full' or 'semi'\n",
    "    \"\"\"\n",
    "\n",
    "    if criterion is None:\n",
    "        raise Exception(\"Missing criterion. You must specify a loss function.\")\n",
    "\n",
    "    net.to(device)\n",
    "\n",
    "    save_epoch = epoch // 20 if epoch > 20 else 1\n",
    "\n",
    "    losses = np.zeros(1000000)\n",
    "    mean_losses = np.zeros(100000000)\n",
    "    iter_ = 1\n",
    "    loss_win, val_win = None, None\n",
    "    val_accuracies = []\n",
    "\n",
    "    for e in tqdm(range(1, epoch + 1), desc=\"Training the network\"):\n",
    "        # Set the network to training mode\n",
    "        net.train()\n",
    "        avg_loss = 0.\n",
    "\n",
    "        # Run the training loop for one epoch\n",
    "        for batch_idx, (data, target) in tqdm(enumerate(data_loader), total=len(data_loader)):\n",
    "            # Load the data into the GPU if required\n",
    "            data, target = data.to(device), target.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            if supervision == 'full':\n",
    "                output = net(data)\n",
    "                # target = target - 1\n",
    "                loss = criterion(output, target)\n",
    "            elif supervision == 'semi':\n",
    "                outs = net(data)\n",
    "                output, rec = outs\n",
    "                # target = target - 1\n",
    "                loss = criterion[0](output, target) + net.aux_loss_weight * criterion[1](rec, data)\n",
    "            else:\n",
    "                raise ValueError(\"supervision mode \\\"{}\\\" is unknown.\".format(supervision))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            avg_loss += loss.item()\n",
    "            losses[iter_] = loss.item()\n",
    "            mean_losses[iter_] = np.mean(losses[max(0, iter_ - 100):iter_ + 1])\n",
    "\n",
    "            if display_iter and iter_ % display_iter == 0:\n",
    "                string = 'Train (epoch {}/{}) [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'\n",
    "                string = string.format(\n",
    "                    e, epoch, batch_idx *\n",
    "                              len(data), len(data) * len(data_loader),\n",
    "                              100. * batch_idx / len(data_loader), mean_losses[iter_])\n",
    "                update = None if loss_win is None else 'append'\n",
    "                try:\n",
    "                    loss_win = display.line(\n",
    "                        X=np.arange(iter_ - display_iter, iter_),\n",
    "                        Y=mean_losses[iter_ - display_iter:iter_],\n",
    "                        win=loss_win,\n",
    "                        update=update,\n",
    "                        opts={'title': \"Training loss\",\n",
    "                              'xlabel': \"Iterations\",\n",
    "                              'ylabel': \"Loss\"\n",
    "                              }\n",
    "                         )\n",
    "                except Exception as a:\n",
    "                        pass\n",
    "               \n",
    "                tqdm.write(string)\n",
    "\n",
    "                if len(val_accuracies) > 0:\n",
    "                    try:\n",
    "                        val_win = display.line(Y=np.array(val_accuracies),\n",
    "                                               X=np.arange(len(val_accuracies)),\n",
    "                                               win=val_win,\n",
    "                                               opts={'title': \"Validation accuracy\",\n",
    "                                                     'xlabel': \"Epochs\",\n",
    "                                                     'ylabel': \"Accuracy\"\n",
    "                                                     })\n",
    "                    except Exception as e:\n",
    "                        pass\n",
    "            iter_ += 1\n",
    "            del (data, target, loss, output)\n",
    "\n",
    "        # Update the scheduler\n",
    "        avg_loss /= len(data_loader)\n",
    "        if val_loader is not None:\n",
    "            val_acc = val(net, val_loader, device=device, supervision=supervision)\n",
    "            val_accuracies.append(val_acc)\n",
    "            metric = -val_acc\n",
    "        else:\n",
    "            metric = avg_loss\n",
    "\n",
    "        if isinstance(scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(metric)\n",
    "        elif scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save the weights\n",
    "        print(e)\n",
    "        if e % save_epoch == 0:\n",
    "            save_model(net, camel_to_snake(str(net.__class__.__name__)), data_loader.dataset.name, epoch=e,\n",
    "                       metric=abs(metric))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step=10, window_size=(20, 20), with_data=True):\n",
    "    \"\"\"Sliding window generator over an input image.\n",
    "\n",
    "    Args:\n",
    "        image: 2D+ image to slide the window on, e.g. RGB or hyperspectral\n",
    "        step: int stride of the sliding window\n",
    "        window_size: int tuple, width and height of the window\n",
    "        with_data (optional): bool set to True to return both the data and the\n",
    "        corner indices\n",
    "    Yields:\n",
    "        ([data], x, y, w, h) where x and y are the top-left corner of the\n",
    "        window, (w,h) the window size\n",
    "\n",
    "    \"\"\"\n",
    "    # slide a window across the image\n",
    "    w, h = window_size\n",
    "    W, H = image.shape[:2]\n",
    "    offset_w = (W - w) % step\n",
    "    offset_h = (H - h) % step\n",
    "    for x in range(0, W - w + offset_w, step):\n",
    "        if x + w > W:\n",
    "            x = W - w\n",
    "        for y in range(0, H - h + offset_h, step):\n",
    "            if y + h > H:\n",
    "                y = H - h\n",
    "            if with_data:\n",
    "                yield image[x:x + w, y:y + h], x, y, w, h\n",
    "            else:\n",
    "                yield x, y, w, h\n",
    "\n",
    "\n",
    "def count_sliding_window(top, step=10, window_size=(20, 20)):\n",
    "    \"\"\" Count the number of windows in an image.\n",
    "\n",
    "    Args:\n",
    "        image: 2D+ image to slide the window on, e.g. RGB or hyperspectral, ...\n",
    "        step: int stride of the sliding window\n",
    "        window_size: int tuple, width and height of the window\n",
    "    Returns:\n",
    "        int number of windows\n",
    "    \"\"\"\n",
    "    sw = sliding_window(top, step, window_size, with_data=False)\n",
    "    return sum(1 for _ in sw)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, img,  patch_size,center_pixel, batch_size, n_classes):\n",
    "    \"\"\"\n",
    "    Test a model on a specific image\n",
    "    \"\"\"\n",
    "    net.eval()\n",
    "    patch_size = patch_size\n",
    "    center_pixel =center_pixel\n",
    "    batch_size, device =batch_size, 'cpu'\n",
    "    n_classes = n_classes\n",
    "\n",
    "    kwargs = {'step': 1, 'window_size': (patch_size, patch_size)}\n",
    "    probs = np.zeros(img.shape[:2] + (n_classes,))\n",
    "\n",
    "    iterations = count_sliding_window(img, **kwargs) // batch_size\n",
    "    for batch in tqdm(grouper(batch_size, sliding_window(img, **kwargs)),\n",
    "                      total=(iterations),\n",
    "                      desc=\"Inference on the image\"\n",
    "                      ):\n",
    "        with torch.no_grad():\n",
    "            if patch_size == 1:\n",
    "                data = [b[0][0, 0] for b in batch]\n",
    "                data = np.copy(data)\n",
    "                data = torch.from_numpy(data)\n",
    "            else:\n",
    "                data = [b[0] for b in batch]\n",
    "                data = np.copy(data)\n",
    "                data = data.transpose(0, 3, 1, 2)\n",
    "                data = torch.from_numpy(data)\n",
    "                data = data.unsqueeze(1)\n",
    "\n",
    "            indices = [b[1:] for b in batch]\n",
    "            data = data.to(device)\n",
    "            output = net(data)\n",
    "            if isinstance(output, tuple):\n",
    "                output = output[0]\n",
    "            output = output.to('cpu')\n",
    "\n",
    "            if patch_size == 1 or center_pixel:\n",
    "                output = output.numpy()\n",
    "            else:\n",
    "                output = np.transpose(output.numpy(), (0, 2, 3, 1))\n",
    "            for (x, y, w, h), out in zip(indices, output):\n",
    "                if center_pixel:\n",
    "                    probs[x + w // 2, y + h // 2] += out\n",
    "                else:\n",
    "                    probs[x:x + w, y:y + h] += out\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val(net, data_loader, device='cpu', supervision='full'):\n",
    "    # TODO : fix me using metrics()\n",
    "    accuracy, total = 0., 0.\n",
    "    ignored_labels = data_loader.dataset.ignored_labels\n",
    "    for batch_idx, (data, target) in enumerate(data_loader):\n",
    "        with torch.no_grad():\n",
    "            # Load the data into the GPU if required\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            if supervision == 'full':\n",
    "                output = net(data)\n",
    "            elif supervision == 'semi':\n",
    "                outs = net(data)\n",
    "                output, rec = outs\n",
    "            _, output = torch.max(output, dim=1)\n",
    "            # target = target - 1\n",
    "            for out, pred in zip(output.view(-1), target.view(-1)):\n",
    "                if out.item() in ignored_labels:\n",
    "                    continue\n",
    "                else:\n",
    "                    accuracy += out.item() == pred.item()\n",
    "                    total += 1\n",
    "    return accuracy / total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7174 samples selected (over 10249)\n",
      "Running an experiment with the nn model run 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the network:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "  0%|          | 0/68 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network :\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 2048]         411,648\n",
      "            Linear-2                 [-1, 4096]       8,392,704\n",
      "            Linear-3                 [-1, 2048]       8,390,656\n",
      "            Linear-4                   [-1, 17]          34,833\n",
      "================================================================\n",
      "Total params: 17,229,841\n",
      "Trainable params: 17,229,841\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 65.73\n",
      "Estimated Total Size (MB): 65.79\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  1%|▏         | 1/68 [00:00<00:21,  3.07it/s]\u001b[A\n",
      "  3%|▎         | 2/68 [00:00<00:21,  3.09it/s]\u001b[A\n",
      "  4%|▍         | 3/68 [00:00<00:21,  3.05it/s]\u001b[A\n",
      "  6%|▌         | 4/68 [00:01<00:21,  3.03it/s]\u001b[A\n",
      "  7%|▋         | 5/68 [00:01<00:20,  3.03it/s]\u001b[A\n",
      "  9%|▉         | 6/68 [00:02<00:21,  2.95it/s]\u001b[A\n",
      " 10%|█         | 7/68 [00:02<00:20,  2.97it/s]\u001b[A\n",
      " 12%|█▏        | 8/68 [00:02<00:20,  2.99it/s]\u001b[A\n",
      " 13%|█▎        | 9/68 [00:02<00:19,  3.01it/s]\u001b[A\n",
      " 15%|█▍        | 10/68 [00:03<00:19,  3.03it/s]\u001b[A\n",
      " 16%|█▌        | 11/68 [00:03<00:18,  3.05it/s]\u001b[A\n",
      " 18%|█▊        | 12/68 [00:03<00:18,  3.02it/s]\u001b[A\n",
      " 19%|█▉        | 13/68 [00:04<00:18,  3.01it/s]\u001b[A\n",
      " 21%|██        | 14/68 [00:04<00:17,  3.03it/s]\u001b[A\n",
      " 22%|██▏       | 15/68 [00:04<00:17,  3.04it/s]\u001b[A\n",
      " 24%|██▎       | 16/68 [00:05<00:17,  3.04it/s]\u001b[A\n",
      " 25%|██▌       | 17/68 [00:05<00:16,  3.04it/s]\u001b[A\n",
      " 26%|██▋       | 18/68 [00:05<00:16,  3.09it/s]\u001b[A\n",
      " 28%|██▊       | 19/68 [00:06<00:15,  3.09it/s]\u001b[A\n",
      " 29%|██▉       | 20/68 [00:06<00:16,  2.99it/s]\u001b[A\n",
      " 31%|███       | 21/68 [00:07<00:17,  2.70it/s]\u001b[A\n",
      " 32%|███▏      | 22/68 [00:07<00:18,  2.44it/s]\u001b[A\n",
      " 34%|███▍      | 23/68 [00:08<00:19,  2.27it/s]\u001b[A\n",
      " 35%|███▌      | 24/68 [00:08<00:20,  2.14it/s]\u001b[A\n",
      " 37%|███▋      | 25/68 [00:09<00:20,  2.07it/s]\u001b[A\n",
      " 38%|███▊      | 26/68 [00:09<00:21,  1.92it/s]\u001b[A\n",
      " 40%|███▉      | 27/68 [00:10<00:22,  1.86it/s]\u001b[A\n",
      " 41%|████      | 28/68 [00:10<00:21,  1.87it/s]\u001b[A\n",
      " 43%|████▎     | 29/68 [00:11<00:20,  1.91it/s]\u001b[A\n",
      " 44%|████▍     | 30/68 [00:11<00:19,  1.93it/s]\u001b[A\n",
      " 46%|████▌     | 31/68 [00:12<00:19,  1.93it/s]\u001b[A\n",
      " 47%|████▋     | 32/68 [00:12<00:18,  1.97it/s]\u001b[A\n",
      " 49%|████▊     | 33/68 [00:13<00:18,  1.93it/s]\u001b[A\n",
      " 50%|█████     | 34/68 [00:13<00:18,  1.84it/s]\u001b[A\n",
      " 51%|█████▏    | 35/68 [00:14<00:18,  1.80it/s]\u001b[A\n",
      " 53%|█████▎    | 36/68 [00:15<00:17,  1.85it/s]\u001b[A\n",
      " 54%|█████▍    | 37/68 [00:15<00:16,  1.89it/s]\u001b[A\n",
      " 56%|█████▌    | 38/68 [00:16<00:15,  1.91it/s]\u001b[A\n",
      " 57%|█████▋    | 39/68 [00:16<00:15,  1.91it/s]\u001b[A\n",
      " 59%|█████▉    | 40/68 [00:17<00:14,  1.90it/s]\u001b[A\n",
      " 60%|██████    | 41/68 [00:17<00:15,  1.76it/s]\u001b[A\n",
      " 62%|██████▏   | 42/68 [00:18<00:14,  1.74it/s]\u001b[A\n",
      " 63%|██████▎   | 43/68 [00:18<00:14,  1.76it/s]\u001b[A\n",
      " 65%|██████▍   | 44/68 [00:19<00:13,  1.79it/s]\u001b[A\n",
      " 66%|██████▌   | 45/68 [00:20<00:12,  1.82it/s]\u001b[A\n",
      " 68%|██████▊   | 46/68 [00:20<00:11,  1.88it/s]\u001b[A\n",
      " 69%|██████▉   | 47/68 [00:21<00:11,  1.88it/s]\u001b[A\n",
      " 71%|███████   | 48/68 [00:21<00:10,  1.90it/s]\u001b[A\n",
      " 72%|███████▏  | 49/68 [00:22<00:09,  1.92it/s]\u001b[A\n",
      " 74%|███████▎  | 50/68 [00:22<00:09,  1.82it/s]\u001b[A\n",
      " 75%|███████▌  | 51/68 [00:23<00:09,  1.77it/s]\u001b[A\n",
      " 76%|███████▋  | 52/68 [00:23<00:08,  1.80it/s]\u001b[A\n",
      " 78%|███████▊  | 53/68 [00:24<00:08,  1.86it/s]\u001b[A\n",
      " 79%|███████▉  | 54/68 [00:24<00:07,  1.89it/s]\u001b[A\n",
      " 81%|████████  | 55/68 [00:25<00:06,  1.92it/s]\u001b[A\n",
      " 82%|████████▏ | 56/68 [00:25<00:06,  1.89it/s]\u001b[A\n",
      " 84%|████████▍ | 57/68 [00:26<00:05,  1.89it/s]\u001b[A\n",
      " 85%|████████▌ | 58/68 [00:26<00:05,  1.86it/s]\u001b[A\n",
      " 87%|████████▋ | 59/68 [00:27<00:04,  1.88it/s]\u001b[A\n",
      " 88%|████████▊ | 60/68 [00:27<00:04,  1.90it/s]\u001b[A\n",
      " 90%|████████▉ | 61/68 [00:28<00:03,  1.89it/s]\u001b[A\n",
      " 91%|█████████ | 62/68 [00:29<00:03,  1.88it/s]\u001b[A\n",
      " 93%|█████████▎| 63/68 [00:29<00:02,  1.90it/s]\u001b[A\n",
      " 94%|█████████▍| 64/68 [00:30<00:02,  1.89it/s]\u001b[A\n",
      " 96%|█████████▌| 65/68 [00:30<00:01,  1.89it/s]\u001b[A\n",
      " 97%|█████████▋| 66/68 [00:31<00:01,  1.81it/s]\u001b[A\n",
      " 99%|█████████▊| 67/68 [00:31<00:00,  1.79it/s]\u001b[A\n",
      "100%|██████████| 68/68 [00:32<00:00,  2.11it/s]\u001b[A\n",
      "Training the network:   0%|          | 0/1 [00:32<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Saving neural network weights in run_epoch1_0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training the network: 100%|██████████| 1/1 [00:32<00:00, 32.85s/it]\n",
      "Inference on the image: 208it [00:12, 16.60it/s]                         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 3  3  3 ... 10 10 10]\n",
      "[11 11 11 ... 11 11 11]\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   1   0   0   0   0   0  13   0   0   0   0   0   0   0   0]\n",
      " [  0   0 159   0   0   0   1   0   1   0   0 267   0   0   0   0   0]\n",
      " [  0   0  28   0   0   0   0   0   0   0   0 221   0   0   0   0   0]\n",
      " [  0   0  42   0   0   0   7   0   0   0   0  22   0   0   0   0   0]\n",
      " [  0   0   6   0   0   3  42   0   6   0   0   0   0   0  88   0   0]\n",
      " [  0   0   1   0   0   2 210   0   5   0   0   0   0   0   1   0   0]\n",
      " [  0   0   0   0   0   0   0   0   8   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0 143   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   6   0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0  12   0   0   0   0   0   2   0   0 278   0   0   0   0   0]\n",
      " [  0   0  31   0   0   0   7   0   3   0   0 696   0   0   0   0   0]\n",
      " [  0   0  31   0   0   0   1   0   0   0   0 145   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0  59   0   0   0   0   0   0   2   0   0   0]\n",
      " [  0   0   0   0   0   1  12   0   0   0   0   0   0   0 367   0   0]\n",
      " [  0   0   2   1   0   1  76   0   0   0   0   0   0   0  34   0   2]\n",
      " [  0   0   3   0   0   0   0   0   0   0   0   1   0   0   0   0  24]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-33-13c3e1d50826>:43: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  F1 = 2. * cm[i, i] / (np.sum(cm[i, :]) + np.sum(cm[:, i]))\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "for run in range(1):\n",
    "    train_gt, test_gt = sample_gt(ground_truth, 0.7, mode='random')\n",
    "    print(\"{} samples selected (over {})\".format(np.count_nonzero(train_gt),\n",
    "                                                 np.count_nonzero(ground_truth)))\n",
    "    print(\"Running an experiment with the {} model\".format('nn'),\n",
    "          \"run {}/{}\".format(run + 1,1))\n",
    "    \n",
    "    n_classes = N_CLASSES\n",
    "    n_bands = N_BANDS\n",
    "    weights = torch.ones(n_classes)\n",
    "    weights[torch.LongTensor(ignored_labels)] = 0.\n",
    "#     weights = weights.to(device)\n",
    "    patch_size = 1\n",
    "    center_pixel = True\n",
    "    model = Baseline(n_bands, n_classes, dropout=False)\n",
    "    learning_rate = 0.0001\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.CrossEntropyLoss(weight = weights)\n",
    "    epoch = 1\n",
    "    batch_size = 100\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, patience=epoch // 4, verbose=True)\n",
    "    supervision = 'full'\n",
    "    flip_augmentation = False\n",
    "    radiation_augmentation = False\n",
    "    mixture_augmentation = False\n",
    "    train_gt, val_gt = sample_gt(train_gt, 0.95, mode='random')\n",
    "    \n",
    "    # Generate the dataset\n",
    "    train_dataset = HyperX(images, train_gt,\n",
    "                           patch_size,\n",
    "                           center_pixel,\n",
    "                           flip_augmentation,\n",
    "                           radiation_augmentation,\n",
    "                           mixture_augmentation,\n",
    "                           supervision)\n",
    "    \n",
    "    train_loader = info_data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_dataset = HyperX(images, val_gt,\n",
    "                         patch_size,\n",
    "                         center_pixel,\n",
    "                         flip_augmentation,\n",
    "                         radiation_augmentation,\n",
    "                         mixture_augmentation,\n",
    "                         supervision)\n",
    "    val_loader = info_data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    print(\"Network :\")\n",
    "    with torch.no_grad():\n",
    "        for input, _ in train_loader:\n",
    "            break\n",
    "    # summary(model.to(hyperparams['device']), input.size()[1:], device=hyperparams['device'])\n",
    "    summary(model, input.size()[1:])\n",
    "    \n",
    "    try:\n",
    "        train(model, optimizer, criterion, train_loader, epoch, val_loader=val_loader)\n",
    "    except KeyboardInterrupt:\n",
    "        # Allow the user to stop the training\n",
    "        pass\n",
    "    \n",
    "    probabilities = test(model, images, patch_size,center_pixel, batch_size, n_classes)\n",
    "#         patch_size = hyperparams['patch_size']\n",
    "#     center_pixel = hyperparams['center_pixel']\n",
    "#     batch_size, device = hyperparams['batch_size'], hyperparams['device']\n",
    "#     n_classes = hyperparams['n_classes']\n",
    "\n",
    "#     kwargs = {'step': hyperparams['test_stride'], 'window_size': (patch_size, patch_size)}\n",
    "    prediction = np.argmax(probabilities, axis=-1)\n",
    "    \n",
    "    run_results = metrics(prediction, test_gt, ignored_labels=ignored_labels, n_classes=N_CLASSES)\n",
    "    \n",
    "    mask = np.zeros(ground_truth.shape, dtype='bool')\n",
    "    for l in ignored_labels:\n",
    "        mask[ground_truth == l] = True\n",
    "    prediction[mask] = 0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
